{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ed21b006/my-public-repo/blob/main/EfficientNet_AdityaRaj_ED21B006.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fromfrom google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VMJ4av3_YGjM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "54ecc810-9e84-4abd-9391-57bc4ab9d173"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-f7ebd81f4251>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    fromfrom google.colab import drive\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip3 install pyprind\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "hUT0FSfTbvoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading and Preparing the Dataset\n",
        "\n",
        "!gdown --id 1oYnD7Izl3LVVzjEMyLxLklX30TKWHgGG\n",
        "!unzip /content/cifar-10.zip\n",
        "!rm -rf /content/cifar-10.zip\n",
        "!mv /content/cifar-10/sample_submission.csv /content/cifar-10/test_labels.csv\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "OvfFGB6UbB8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import pandas\n",
        "import numpy\n",
        "from sklearn import preprocessing\n",
        "import matplotlib\n",
        "\n",
        "import os\n",
        "import pyprind\n",
        "\n",
        "PATH = \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "OdMFciI7WQkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CreateDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir, mode='train'):\n",
        "        self.root_dir = root_dir\n",
        "        self.mode = mode\n",
        "\n",
        "        self.entry = pandas.read_csv(os.path.join(self.root_dir, f'{self.mode}_labels.csv'))\n",
        "        self.encoder = self._process_()\n",
        "        self.entry['label'] = self.encoder.transform(self.entry['label'])\n",
        "\n",
        "        self.transform = torchvision.transforms.Compose(\n",
        "            [\n",
        "                torchvision.transforms.Resize((32,32)),  # LeNet requires input to be of 32x32 pixels \n",
        "                torchvision.transforms.ToTensor()\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def _process_(self):\n",
        "        data = pandas.read_csv(os.path.join(self.root_dir, 'train_labels.csv'))\n",
        "        encoder = preprocessing.LabelEncoder()\n",
        "        encoder.fit(data['label'])\n",
        "        return encoder\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data = self.entry.iloc[index]\n",
        "        image = Image.open(f\"/content/cifar-10/train/{data['id']}.png\") \n",
        "        image = self.transform(image)\n",
        "        label = data['label']\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.entry)"
      ],
      "metadata": {
        "id": "xj-_3MeLVuz-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "698032e8-afbb-4832-f358-88eca0a6a554"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-150cd28fa5d5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCreateDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(torch.nn.Module):\n",
        "    def __init__(self, model_name='efficientnet-b0', num_classes=10):\n",
        "        super(Network, self).__init__()\n",
        "        self.model = EfficientNet.from_pretrained(model_name)\n",
        "        self.model._fc = nn.Linear(self.model._fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "xhpnlVPlWfVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer():\n",
        "    def __init__(self, data):\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.trainloader, self.validloader, self.testloader = self.get_iterator(data)\n",
        "        \n",
        "        self.model = self.get_model().to(self.device)\n",
        "        self.criterion = self.get_criterion().to(self.device)\n",
        "        self.optimizer = self.get_optimizer()\n",
        "\n",
        "        self.train_loss = []\n",
        "        self.train_metrics = []\n",
        "        self.valid_loss = []\n",
        "        self.valid_metrics = []\n",
        "\n",
        "        self.epochs = 10\n",
        "\n",
        "    def get_iterator(self, data):\n",
        "        train, valid, test = data\n",
        "        trainloader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=True, drop_last=True) \n",
        "        validloader = torch.utils.data.DataLoader(valid, batch_size=64, shuffle=False, drop_last=True) \n",
        "        testloader = torch.utils.data.DataLoader(test, batch_size=64, shuffle=False) \n",
        "        return trainloader, validloader, testloader\n",
        "\n",
        "    def get_criterion(self):\n",
        "        return torch.nn.CrossEntropyLoss() \n",
        "    \n",
        "    def get_optimizer(self):\n",
        "        return torch.optim.SGD(self.model.parameters(), lr=0.01, momentum=0.9) \n",
        "\n",
        "    def get_model(self):\n",
        "        model = Network() \n",
        "        return model\n",
        "\n",
        "    def save(self, epoch):\n",
        "        torch.save({\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            }, os.path.join(PATH, \"model.pth\"))\n",
        "        \n",
        "    def load(self):\n",
        "        if os.path.exists(os.path.join(PATH, \"model.pth\")):\n",
        "            checkpoints = torch.load(os.path.join(self.args.checkpoint, \"model.pth\"), map_location=self.device)\n",
        "            self.model.load_state_dict(checkpoints['model_state_dict'])\n",
        "            self.optimizer.load_state_dict(checkpoints['optimizer_state_dict'])\n",
        "\n",
        "    def train(self):\n",
        "        epoch_loss = 0\n",
        "        epoch_metrics = {}\n",
        "\n",
        "        self.model.train()\n",
        "\n",
        "        with torch.autograd.set_detect_anomaly(True):\n",
        "            bar = pyprind.ProgBar(len(self.trainloader), bar_char='█')\n",
        "            for index, (image, label) in enumerate(self.trainloader):  # for batches. 1 loop 1 batch. [total/64] iterations\n",
        "                image = image.to(self.device)\n",
        "                label = label.to(self.device)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                \n",
        "                output = self.model(image) \n",
        "\n",
        "                loss = self.criterion(output,label) \n",
        "\n",
        "                loss.backward() \n",
        "                epoch_loss += loss\n",
        "\n",
        "                self.optimizer.step()\n",
        "                bar.update()\n",
        "        epoch_loss /= len(self.trainloader)\n",
        "\n",
        "        return epoch_loss, epoch_metrics\n",
        "\n",
        "    def evaluate(self):\n",
        "        epoch_loss = 0\n",
        "        epoch_metrics = {}\n",
        "\n",
        "        with torch.autograd.set_detect_anomaly(True):\n",
        "            bar = pyprind.ProgBar(len(self.validloader), bar_char='█')\n",
        "            for index, (image, label) in enumerate(self.validloader):\n",
        "                image = image.to(self.device)\n",
        "                label = label.to(self.device)\n",
        "                \n",
        "                output = self.model(image) \n",
        "\n",
        "                loss = self.criterion(output,label) \n",
        "                epoch_loss += loss\n",
        "\n",
        "                bar.update()\n",
        "        epoch_loss /= len(self.validloader)\n",
        "\n",
        "        return epoch_loss, epoch_metrics\n",
        "\n",
        "    def test(self):\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        outputs = torch.empty([0,])\n",
        "\n",
        "        with torch.autograd.set_detect_anomaly(True):\n",
        "            bar = pyprind.ProgBar(len(self.testloader), bar_char='█')\n",
        "            for index, (image, label) in enumerate(self.testloader):\n",
        "                image = image.to(self.device)\n",
        "                label = label.to(self.device)\n",
        "                \n",
        "                output = self.model(image) \n",
        "                outputs = torch.cat((outputs, output), dim=0)\n",
        "\n",
        "                bar.update()\n",
        "\n",
        "        return outputs\n",
        "    \n",
        "    def fit(self):\n",
        "        # epochs=10\n",
        "        for epoch in range(1, self.epochs+1, 1):\n",
        "\n",
        "            epoch_train_loss, epoch_train_metrics = self.train()\n",
        "\n",
        "            self.train_loss.append(epoch_train_loss)\n",
        "            self.train_metrics.append(epoch_train_metrics)\n",
        "\n",
        "            epoch_valid_loss, epoch_valid_metrics = self.evaluate()\n",
        "            \n",
        "            self.valid_loss.append(epoch_valid_loss)\n",
        "            self.valid_metrics.append(epoch_valid_metrics) \n",
        "\n",
        "            print(f'Epoch {epoch}/{self.epochs+1}: Train Loss = {epoch_train_loss} | Validation Loss = {epoch_valid_loss}')\n",
        "\n",
        "            # if epoch_valid_metrics >= max(self.valid_metrics):\n",
        "            if epoch_valid_loss<=min(self.valid_loss):\n",
        "                self.save(epoch)"
      ],
      "metadata": {
        "id": "tYHk4v5-WrfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = CreateDataset(root_dir=\"/content/cifar-10/\", mode=\"train\")\n",
        "train_data, valid_data = torch.utils.data.random_split(train_data, [len(train_data)-len(train_data)//10, len(train_data)//10])\n",
        "test_data = CreateDataset(root_dir=\"/content/cifar-10/\", mode=\"test\")\n",
        "data = (train_data, valid_data, test_data)\n",
        "\n",
        "trainer = Trainer(data)\n",
        "trainer.fit()\n",
        "\n",
        "outputs = trainer.test()"
      ],
      "metadata": {
        "id": "e2VnYXVYYaqF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}